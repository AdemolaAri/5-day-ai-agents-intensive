{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba50b048",
   "metadata": {},
   "source": [
    "# AgentFleet: Multi-Agent Emergency Response System\n",
    "## Agents for Good â€” A Comprehensive Demonstration\n",
    "\n",
    "Welcome to the AgentFleet demonstration! This capstone project showcases a **multi-agent system designed to save lives and protect communities** through intelligent emergency response and incident management using Google's Agent Development Kit (ADK).\n",
    "\n",
    "### ðŸŒ Why This Matters: Agents for Good\n",
    "\n",
    "AgentFleet represents how AI agents can benefit entire communities by:\n",
    "- **Reducing Response Time**: Automating incident triage and dispatch coordination\n",
    "- **Improving Accuracy**: Verifying claims and assessing reliability across multiple sources\n",
    "- **Saving Lives**: Prioritizing critical incidents for faster emergency response\n",
    "- **Supporting First Responders**: Handling data processing so human operators can focus on action\n",
    "\n",
    "This demo is a **proof-of-concept for what's possible**â€”imagine scaling this to coordinate emergency response across cities, regions, or entire nations.\n",
    "\n",
    "### ðŸŽ¯ Project Overview\n",
    "\n",
    "AgentFleet is an advanced multi-agent system that processes emergency events through a sophisticated pipeline of specialized AI agents:\n",
    "\n",
    "1. **Ingest Agent** - Normalizes raw event data from various sources (social media, sensors, emergency feeds)\n",
    "2. **Verifier Agent** - Verifies claims and assesses source reliability to reduce false alarms\n",
    "3. **Summarizer Agent** - Creates concise incident summaries with historical context for operators\n",
    "4. **Triage Agent** - Classifies incident severity (LOW, MEDIUM, HIGH, CRITICAL) for prioritization\n",
    "5. **Dispatcher Agent** - Generates actionable recommendations and communicates with response teams\n",
    "6. **Dashboard Agent** - Creates markdown dashboards for human operators to visualize and manage emergency response operations\n",
    "\n",
    "### ðŸ—ï¸ Architecture\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Event Sources] --> B[Ingest Agent]\n",
    "    B --> C[Verifier Agent]\n",
    "    C --> D[Summarizer Agent]\n",
    "    D --> E[Triage Agent]\n",
    "    E --> F[Dispatcher Agent]\n",
    "    F --> G[Emergency Response Teams]\n",
    "```\n",
    "\n",
    "### ðŸ“‹ Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e87805",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "This section initializes the AgentFleet system and configures dependencies for the multi-agent emergency response pipeline.\n",
    "\n",
    "### 1.1 Project Root Configuration\n",
    "\n",
    "First, we establish the project root directory by locating the `capstone` module. \n",
    "This ensures the notebook can access all capstone modules regardless of where it's executed from.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a7c3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Project root set to: /Users/ademola-ari/Projects/5-day-ai-agents-intensive\n",
      "âœ… capstone imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# %%writefile fleet-agent/agent.py\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Walk up until we find \"capstone\" folder\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if (parent / \"capstone\" / \"__init__.py\").exists():\n",
    "        sys.path.insert(0, str(parent))\n",
    "        print(\"ðŸ“ Project root set to:\", parent)\n",
    "        break\n",
    "\n",
    "import capstone\n",
    "print(\"âœ… capstone imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf7d034",
   "metadata": {},
   "source": [
    "### 1.2 Google API Authentication\n",
    "Next, we authenticate with Google's API services. The system attempts to load credentials from environment variables, with a fallback to manual entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ceddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Google API key obtained successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "# Load environment variables from .env file if it exists\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# read from environment variable\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# if missing, prompt user to enter the API key\n",
    "if not GOOGLE_API_KEY:\n",
    "    GOOGLE_API_KEY = input(\"Enter your Google API key: \")\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    print(\"âŒ Error: Google API key is required. Please set the 'GOOGLE_API_KEY' environment variable or enter it when prompted.\")\n",
    "else:\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "    print(\"âœ… Google API key obtained successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae35abc",
   "metadata": {},
   "source": [
    "### 1.3 ADK Components Import\n",
    "We then import all necessary Agent Development Kit (ADK) modules and dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "788cc5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# %%writefile -a fleet-agent/agent.py\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "from google.adk.agents import Agent, LlmAgent, SequentialAgent\n",
    "from google.adk.agents.remote_a2a_agent import (\n",
    "    RemoteA2aAgent,\n",
    "    AGENT_CARD_WELL_KNOWN_PATH,\n",
    ")\n",
    "\n",
    "from google.adk.a2a.utils.agent_to_a2a import to_a2a\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner, Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "\n",
    "# Hide additional warnings in the notebook\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438ef845",
   "metadata": {},
   "source": [
    "### 1.4 Retry Configuration\n",
    "Finally, we configure HTTP retry logic for resilient API communication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f8113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Retry configuration set.\n"
     ]
    }
   ],
   "source": [
    "# %%writefile -a fleet-agent/agent.py\n",
    "\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")\n",
    "\n",
    "print(\"âœ… Retry configuration set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc34114",
   "metadata": {},
   "source": [
    "## 2. Ingest Agent Setup\n",
    "\n",
    "The Ingest Agent is the first component in the AgentFleet pipeline. It connects to multiple event sources, normalizes incoming data, and prepares events for downstream agents.\n",
    "\n",
    "### 2.1 Starting the Ingest Agent A2A Server\n",
    "\n",
    "We launch the Ingest Agent as a background service using **Uvicorn**, an ASGI application server. This makes the agent accessible via HTTP as an Agent-to-Agent (A2A) service:\n",
    "\n",
    "- **Service Type**: Python application running on localhost\n",
    "- **Port**: 8001\n",
    "- **Protocol**: HTTP REST with well-known agent card discovery\n",
    "- **Module**: `capstone.agents.ingest_agent:app`\n",
    "\n",
    "The notebook waits for the server to be ready before proceeding, polling the agent card endpoint every 5 seconds with a maximum of 20 attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f703ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ingest Agent code written to capstone/agents/ingest_agent.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile -a fleet-agent/agent.py\n",
    "\n",
    "ingest_agent_code = '''\n",
    "import os\n",
    "from typing import Any, Dict\n",
    "import dotenv\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.a2a.utils.agent_to_a2a import to_a2a\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.genai import types\n",
    "\n",
    "from capstone.tools.stream_simulators import TwitterStreamSimulator, EmergencyFeedSimulator, SensorDataSimulator\n",
    "\n",
    "def generate_single_event(source_type: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate a single event from the specified source type.\n",
    "    \n",
    "    Args:\n",
    "        source_type: Type of stream source (\"twitter\", \"emergency\", \"sensor\")\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the generated event data\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If source_type is not supported\n",
    "    \"\"\"\n",
    "    # Create simulator based on source type\n",
    "    if source_type == \"twitter\":\n",
    "        simulator = TwitterStreamSimulator()\n",
    "    elif source_type == \"emergency\":\n",
    "        simulator = EmergencyFeedSimulator()\n",
    "    elif source_type == \"sensor\":\n",
    "        simulator = SensorDataSimulator()\n",
    "    else:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": f\"Unsupported source_type: {source_type}\"\n",
    "        }\n",
    "    \n",
    "    result = {\n",
    "        \"status\": \"success\",\n",
    "        \"source_type\": source_type,\n",
    "        \"event\": simulator.generate_event()\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# Load environment variables from .env file if it exists\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# read from environment variable\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# if missing, prompt user to enter the API key\n",
    "if not GOOGLE_API_KEY:\n",
    "    GOOGLE_API_KEY = input(\"Enter your Google API key: \")\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    print(\"âŒ Error: Google API key is required. Please set the 'GOOGLE_API_KEY' environment variable or enter it when prompted.\")\n",
    "else:\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "    print(\"âœ… Google API key obtained successfully.\")\n",
    "\n",
    "\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")\n",
    "\n",
    "INGEST_AGENT_INSTRUCTIONS = \"\"\"You are the Ingest Agent in the AgentFleet incident response system.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Call `generate_single_event` to generate a single event from a specified source.\n",
    "2. The event output should be described in detail for further processing.\n",
    "\n",
    "When processing events:\n",
    "- Use the `generate_single_event` tool to generate events\n",
    "- If the event is successfully generated, describe the generated event in detail \n",
    "- Generate unique event IDs\n",
    "- Extract all relevant information from the event source and describe it in detail\n",
    "\n",
    "User will supply the source to extract from e.g \"twitter\", \"emergency_feed\", or \"sensor_data\". Pass this to the `generate_single_event` tool to generate the event.\n",
    "Then describe the generated event in detail in your output.\n",
    "\"\"\"\n",
    "\n",
    "# Create the Ingest Agent\n",
    "ingest_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"ingest_agent\",\n",
    "    description=\"Ingest agent that connects to event sources and extract imformation for processing\",\n",
    "    instruction=INGEST_AGENT_INSTRUCTIONS,\n",
    "    tools=[generate_single_event],\n",
    "    output_key=\"raw_event_json\",\n",
    ")\n",
    "\n",
    "# Create the A2A app\n",
    "app = to_a2a(\n",
    "    ingest_agent, port=8001\n",
    ")\n",
    "'''\n",
    "\n",
    "with open(\"../agents/ingest_agent.py\", \"w\") as f:\n",
    "    f.write(ingest_agent_code)\n",
    "\n",
    "print(\"âœ… Ingest Agent code written to capstone/agents/ingest_agent.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18317636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Ingest Agent A2A server in the background on port 8001.\n",
      "   Waiting for server to be ready...\n",
      ".âœ… Ingest Agent A2A server is ready.\n",
      "   Server URL: http://localhost:8001\n",
      "   Agent Card URL: http://localhost:8001/.well-known/agent-card.json\n"
     ]
    }
   ],
   "source": [
    "# %%writefile -a fleet-agent/agent.py\n",
    "\n",
    "\n",
    "import subprocess, os\n",
    "from pathlib import Path\n",
    "import capstone\n",
    "\n",
    "project_root = Path(capstone.__file__).resolve().parents[1]\n",
    "\n",
    "\n",
    "# Setup to run in background\n",
    "# run agent setup code in capstone/agents/ingest_agent.py for background execution\n",
    "\n",
    "server_process = subprocess.Popen(\n",
    "    [\n",
    "        \"uvicorn\",\n",
    "        \"capstone.agents.ingest_agent:app\",\n",
    "        \"--host\",\n",
    "        \"localhost\",\n",
    "        \"--port\",\n",
    "        \"8001\",\n",
    "    ],\n",
    "    cwd=project_root,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    env={**os.environ},\n",
    ")\n",
    "\n",
    "\n",
    "print(\"ðŸš€ Starting Ingest Agent A2A server in the background on port 8001.\")\n",
    "print(\"   Waiting for server to be ready...\")\n",
    "\n",
    "# Wait for the server to start\n",
    "max_attempts = 20\n",
    "for attempt in range(max_attempts):\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            \"http://localhost:8001/.well-known/agent-card.json\", timeout=1\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            print(\"âœ… Ingest Agent A2A server is ready.\")\n",
    "            print(\"   Server URL: http://localhost:8001\")\n",
    "            print(\"   Agent Card URL: http://localhost:8001/.well-known/agent-card.json\")\n",
    "            break\n",
    "    except requests.exceptions.RequestException:\n",
    "        time.sleep(5)\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Server may not be ready yet. Check manually if needed.\")\n",
    "\n",
    "# Store the process so it can be terminated later if needed\n",
    "globals()[\"ingest_agent_server_process\"] = server_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb66f6e",
   "metadata": {},
   "source": [
    "### 2.2 View the Auto-Generated Agent Card\n",
    "\n",
    "Once the Ingest Agent server is running, we retrieve and display its **agent card**â€”a standardized JSON document that describes the agent's capabilities, exposed skills, and communication interface.\n",
    "\n",
    "The agent card includes:\n",
    "- **Name**: Unique identifier for the agent\n",
    "- **Description**: Purpose and role in the incident response system\n",
    "- **URL**: HTTP endpoint for agent-to-agent communication\n",
    "- **Skills**: List of capabilities and tools the agent exposes to other agents\n",
    "\n",
    "This discovery mechanism enables other agents to dynamically learn what the Ingest Agent can do without hardcoding dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e2480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ingest Agent A2A server is reachable.\n",
      "{\n",
      "  \"capabilities\": {},\n",
      "  \"defaultInputModes\": [\n",
      "    \"text/plain\"\n",
      "  ],\n",
      "  \"defaultOutputModes\": [\n",
      "    \"text/plain\"\n",
      "  ],\n",
      "  \"description\": \"Ingest agent that connects to event sources and extract imformation for processing\",\n",
      "  \"name\": \"ingest_agent\",\n",
      "  \"preferredTransport\": \"JSONRPC\",\n",
      "  \"protocolVersion\": \"0.3.0\",\n",
      "  \"skills\": [\n",
      "    {\n",
      "      \"description\": \"Ingest agent that connects to event sources and extract imformation for processing I am the Ingest Agent in the AgentFleet incident response system.\\n\\nmy responsibilities:\\n1. Call `generate_single_event` to generate a single event from a specified source.\\n2. The event output should be described in detail for further processing.\\n\\nWhen processing events:\\n- Use the `generate_single_event` tool to generate events\\n- If the event is successfully generated, describe the generated event in detail \\n- Generate unique event IDs\\n- Extract all relevant information from the event source and describe it in detail\\n\\nUser will supply the source to extract from e.g \\\"twitter\\\", \\\"emergency_feed\\\", or \\\"sensor_data\\\". Pass this to the `generate_single_event` tool to generate the event.\\nThen describe the generated event in detail in my output.\\n\",\n",
      "      \"id\": \"ingest_agent\",\n",
      "      \"name\": \"model\",\n",
      "      \"tags\": [\n",
      "        \"llm\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"Generate a single event from the specified source type.\\n\\nArgs:\\n    source_type: Type of stream source (\\\"twitter\\\", \\\"emergency\\\", \\\"sensor\\\")\\n\\nReturns:\\n    Dictionary containing the generated event data\\n\\nRaises:\\n    ValueError: If source_type is not supported\",\n",
      "      \"id\": \"ingest_agent-generate_single_event\",\n",
      "      \"name\": \"generate_single_event\",\n",
      "      \"tags\": [\n",
      "        \"llm\",\n",
      "        \"tools\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"supportsAuthenticatedExtendedCard\": false,\n",
      "  \"url\": \"http://localhost:8001\",\n",
      "  \"version\": \"0.0.1\"\n",
      "}\n",
      "\n",
      " Key details:\n",
      " - Name: ingest_agent\n",
      " - Description: Ingest agent that connects to event sources and extract imformation for processing\n",
      " - URL: http://localhost:8001\n",
      " - Skills: 2 capabilities exposed\n"
     ]
    }
   ],
   "source": [
    "# %%writefile -a fleet-agent/agent.py\n",
    "\n",
    "try:\n",
    "    response = requests.get(\n",
    "        \"http://localhost:8001/.well-known/agent-card.json\", timeout=5\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        agent_card = response.json()\n",
    "        print(\"âœ… Ingest Agent A2A server is reachable.\")\n",
    "        print(json.dumps(agent_card, indent=2))\n",
    "\n",
    "        print(\"\\n Key details:\")\n",
    "        print(f\" - Name: {agent_card.get('name')}\")\n",
    "        print(f\" - Description: {agent_card.get('description')}\")\n",
    "        print(f\" - URL: {agent_card.get('url')}\")\n",
    "        print(f\" - Skills: {len(agent_card.get('skills', []))} capabilities exposed\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"âŒ Failed to reach Ingest Agent A2A server. Status code: {response.status_code}\"\n",
    "        )\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"âŒ Error reaching Ingest Agent A2A server: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e620d6",
   "metadata": {},
   "source": [
    "### 2.3 Create Client-Side Proxy to Interact with the Ingest Agent A2A App\n",
    "\n",
    "We instantiate a **RemoteA2aAgent** proxy that acts as a local client for the remote Ingest Agent service. This proxy:\n",
    "\n",
    "- Connects to the agent card endpoint on port 8001\n",
    "- Translates local requests into A2A protocol messages\n",
    "- Handles serialization/deserialization of data\n",
    "- Enables seamless communication between the notebook and the Ingest Agent service\n",
    "\n",
    "The proxy is then added as a sub-agent to the root orchestrating agent, allowing the entire pipeline to work together as a coordinated multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "641c3b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RemoteA2aAgent proxy created for Ingest Agent A2A app.\n",
      "   Connected to: http://localhost:8001\n",
      "   Agent card: http://localhost:8001/.well-known/agent-card.json\n",
      "   Ready to send requests to Ingest Agent.\n"
     ]
    }
   ],
   "source": [
    "# %%writefile -a fleet-agent/agent.py\n",
    "\n",
    "remote_ingest_agent = RemoteA2aAgent(\n",
    "    name=\"remote_ingest_agent\",\n",
    "    description=\"Client-side proxy to interact with the Ingest Agent A2A app\",\n",
    "    agent_card=f\"http://localhost:8001{AGENT_CARD_WELL_KNOWN_PATH}\",\n",
    ")\n",
    "\n",
    "print(\"âœ… RemoteA2aAgent proxy created for Ingest Agent A2A app.\")\n",
    "print(f\"   Connected to: http://localhost:8001\")\n",
    "print(f\"   Agent card: http://localhost:8001{AGENT_CARD_WELL_KNOWN_PATH}\")\n",
    "print(\"   Ready to send requests to Ingest Agent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb81966",
   "metadata": {},
   "source": [
    "![Ingest Agent](../demo/ingest_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3010e10",
   "metadata": {},
   "source": [
    "### Test A2A Interaction with Ingest Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f7808b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RemoteA2aAgent proxy created for Ingest Agent A2A app.\n",
      "   Connected to: http://localhost:8001\n",
      "   Agent card: http://localhost:8001/.well-known/agent-card.json\n",
      "   Ready to send requests to Ingest Agent.\n",
      "âœ… Emergency Response Tester Agent created.\n",
      "   Model: gemini-2.5-flash-lite\n",
      "   Ready to simulate event ingestion via Ingest Agent.\n"
     ]
    }
   ],
   "source": [
    "# Create a test user agent to interact with the Ingest Agent A2A app\n",
    "remote_ingest_agent_test = RemoteA2aAgent(\n",
    "    name=\"remote_ingest_agent_test\",\n",
    "    description=\"Client-side proxy to interact with the Ingest Agent A2A app - test instance\",\n",
    "    agent_card=f\"http://localhost:8001{AGENT_CARD_WELL_KNOWN_PATH}\",\n",
    ")\n",
    "\n",
    "print(\"âœ… RemoteA2aAgent proxy created for Ingest Agent A2A app.\")\n",
    "print(f\"   Connected to: http://localhost:8001\")\n",
    "print(f\"   Agent card: http://localhost:8001{AGENT_CARD_WELL_KNOWN_PATH}\")\n",
    "print(\"   Ready to send requests to Ingest Agent.\")\n",
    "\n",
    "emergency_response_tester_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"emergency_response_tester_agent\",\n",
    "    description=\"Test agent to interact with the Ingest Agent A2A app\",\n",
    "    instruction=\"\"\"You are a test agent that interacts with the Ingest Agent A2A app to simulate emergency event ingestion.\n",
    "    Your tasks:\n",
    "    1. Send requests to the Ingest Agent to ingest events from a simulated stream.\n",
    "    2. Receive and display the normalized events returned by the Ingest Agent.\n",
    "    3. Validate that the events are correctly normalized and contain required fields: location, time, event type.\n",
    "    4. Report any issues or discrepancies found in the normalized events.\n",
    "    \"\"\",\n",
    "    sub_agents=[remote_ingest_agent_test],\n",
    ")\n",
    "\n",
    "print(\"âœ… Emergency Response Tester Agent created.\")\n",
    "print(\"   Model: gemini-2.5-flash-lite\")\n",
    "print(\"   Ready to simulate event ingestion via Ingest Agent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16952e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_ingest_agent_a2a_interaction(query: str):\n",
    "    \"\"\"\n",
    "    Test the A2A communication between the Emergency Response Tester Agent and the Ingest Agent.\n",
    "\n",
    "    Steps:\n",
    "    1. The tester agent sends a request to the Ingest Agent to ingest to get events from a simulated stream.\n",
    "    2. The Ingest Agent processes the request, connects to the stream, normalizes events, and returns the results.\n",
    "    3. The tester agent receives and displays the normalized events\n",
    "\n",
    "    Args:\n",
    "        query (str): The request/query to send to the Ingest Agent.\n",
    "    \"\"\"\n",
    "\n",
    "    session_service = InMemorySessionService()\n",
    "\n",
    "    # Session identifiers\n",
    "    app_name = \"emergency_response_app\"\n",
    "    user_id = \"tester_user\"\n",
    "\n",
    "    session_id = f\"test_session_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "    session = await session_service.create_session(\n",
    "        app_name=app_name, user_id=user_id, session_id=session_id\n",
    "    )\n",
    "\n",
    "    # Create runner for the tester agent\n",
    "    runner = Runner(\n",
    "        agent=emergency_response_tester_agent,\n",
    "        app_name=app_name,\n",
    "        session_service=session_service,\n",
    "    )\n",
    "\n",
    "    # Create the user message\n",
    "    test_content = types.Content(parts=[types.Part(text=query)])\n",
    "\n",
    "    # Display query\n",
    "    print(f\"\\nðŸ§ª Emergency Response Tester: {query}\")\n",
    "    print(f\".    Ingest Agent response:\")\n",
    "    print(\"..................................................\")\n",
    "\n",
    "    # Run the agent asynchronously (handles streaming responses and A2A communication)\n",
    "    async for event in runner.run_async(\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "        new_message=test_content,\n",
    "    ):\n",
    "        # Print final response only (skip intermediate events)\n",
    "        if event.is_final_response() and event.content:\n",
    "            for part in event.content.parts:\n",
    "                if hasattr(part, \"text\"):\n",
    "                    print(part.text)\n",
    "\n",
    "    print(\".\" * 80)\n",
    "    print(\"âœ… Test completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5878f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing A2A Interaction with Ingest Agent ===\n",
      "\n",
      "ðŸ§ª Emergency Response Tester: Ingest latest events from twitter\n",
      ".    Ingest Agent response:\n",
      "..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The event generated from twitter is about a power outage in Oak Avenue. The power restoration efforts are ongoing and may take hours. The event has a tweet ID, user information, and timestamp. It also includes hashtags like #alert. The incident type is logged as power_outage with associated likes and retweets.\n",
      "................................................................................\n",
      "âœ… Test completed.\n"
     ]
    }
   ],
   "source": [
    "# Example test interaction\n",
    "print(\"\\n=== Testing A2A Interaction with Ingest Agent ===\")\n",
    "await test_ingest_agent_a2a_interaction(\n",
    "    \"Ingest latest events from twitter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3563e043",
   "metadata": {},
   "source": [
    "## 3. Verifier Agent Setup\n",
    "\n",
    "The Verifier Agent is the second component in the AgentFleet pipeline. It receives normalized events from the Ingest Agent and validates claims by fact-checking them against reliable sources, then scores the overall reliability of each event.\n",
    "\n",
    "### 3.1 Import Verifier Tools\n",
    "\n",
    "We begin by importing the specialized tools that the Verifier Agent uses to perform its verification tasks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35fe05d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Verifier Agent Successfully Setup\n",
      "   Model: gemini-2.5-flash-lite\n",
      "   Tools: extract_claims_tool(), verify_claim_tool(), score_reliability_tool()\n",
      "   Ready to verify claims from ingested events.\n"
     ]
    }
   ],
   "source": [
    "# %%writefile -a fleet-agent/agent.py\n",
    "\n",
    "# setup verifier agent to receive events from the ingest agent and verify claims\n",
    "from capstone.agents.verifier_agent import (\n",
    "    extract_claims_tool,\n",
    "    verify_claim_tool,\n",
    "    score_reliability_tool\n",
    ")\n",
    "\n",
    "VERIFIER_AGENT_INSTRUCTION = \"\"\"\n",
    "You are the Verifier Agent in the AgentFleet incident response system.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Receive event summary from the Ingest Agent\n",
    "2. Extract verifiable claims from event content\n",
    "3. Fact-check claims using search tools (when available)\n",
    "4. Score source reliability based on verification results\n",
    "\n",
    "When processing events:\n",
    "- Use the `extract_claims_tool` to identify factual statements that can be verified\n",
    "- Use the `verify_claim_tool` to check each claim (with search results if available)\n",
    "- Use the `score_reliability_tool` to calculate overall reliability score (0.0 to 1.0)\n",
    "- Flag events with reliability score below 0.3 as unverified\n",
    "- Explain your reasoning for each claim verification and reliability score in the output\n",
    "\n",
    "Be thorough in verification but efficient in processing.\n",
    "Always include session_id for tracking incident lifecycle.\n",
    "\"\"\"\n",
    "\n",
    "verifier_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"verifier_agent\",\n",
    "    description=\"Verifier agent in the AgentFleet incident response system\",\n",
    "    instruction=VERIFIER_AGENT_INSTRUCTION,\n",
    "    tools=[extract_claims_tool, verify_claim_tool, score_reliability_tool],\n",
    "    output_key=\"verified_claims\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Verifier Agent Successfully Setup\")\n",
    "print(\"   Model: gemini-2.5-flash-lite\")\n",
    "print(\"   Tools: extract_claims_tool(), verify_claim_tool(), score_reliability_tool()\")\n",
    "print(\"   Ready to verify claims from ingested events.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd1283",
   "metadata": {},
   "source": [
    "![Verifier Agent](../demo/verifier_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bea80fe",
   "metadata": {},
   "source": [
    "## 4. Summarizer Agent Setup\n",
    "\n",
    "The Summarizer Agent is the third component in the AgentFleet pipeline. It receives verified events from the Verifier Agent and transforms them into concise, actionable incident briefs for human operators.\n",
    "\n",
    "### 4.1 Import Summarizer Tools\n",
    "\n",
    "We begin by importing the specialized tool that the Summarizer Agent uses to extract and structure key information:\n",
    "\n",
    "The Summarizer Agent performs the following functions:\n",
    "\n",
    "- **Receives verified events** with reliability scores from the Verifier Agent\n",
    "- **Generates concise incident briefs** (maximum 200 words) suitable for rapid operator review\n",
    "- **Extracts key facts** including location, time, affected entities, and impact assessment\n",
    "- **Structures output** with organized information for downstream agents (Triage and Dispatcher)\n",
    "- **Explains reasoning** about which facts were included and why they're important\n",
    "\n",
    "The summarizer uses the `extract_key_facts_tool` to identify and organize critical information from verified claims, ensuring that operators receive clear, focused summaries that enable faster decision-making in emergency response scenarios.\n",
    "\n",
    "**Key Capabilities:**\n",
    "- Concise summarization (max 200 words per incident brief)\n",
    "- Structured fact extraction (location, time, entities, impact)\n",
    "- Pattern identification and similarity scoring\n",
    "- Seamless handoff to Triage Agent for severity classification\n",
    "\n",
    "This agent bridges the gap between verification and incident prioritization, ensuring that critical information is neither lost nor buried in unnecessary detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9419ee74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Summarizer Agent Successfully Setup\n",
      "   Model: gemini-2.5-flash-lite\n",
      "   Tool: extract_key_facts_tool()\n",
      "   Ready to summarize verified events into incident briefs.\n"
     ]
    }
   ],
   "source": [
    "# %%writefile -a fleet-agent/agent.py\n",
    "\n",
    "\n",
    "from capstone.agents.summarizer_agent import extract_key_facts_tool\n",
    "\n",
    "SUMMARIZER_AGENT_INSTRUCTIONS = \"\"\"\n",
    "You are the Summarizer Agent in the AgentFleet incident response system.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Receive verified events from the Verifier Agent\n",
    "2. Generate concise incident briefs (maximum 200 words)\n",
    "3. Extract key facts: location, time, affected entities, impact\n",
    "4. Output incident briefs with structured key facts\n",
    "\n",
    "When processing events:\n",
    "- Generate concise summaries (max 200 words)\n",
    "- Use the `extract_key_facts_tool` to identify structured information\n",
    "- Include similarity scores and patterns in the incident brief\n",
    "- Explain your reasoning in the output, including which facts were included and why\n",
    "\n",
    "Be concise but comprehensive. Focus on actionable information.\n",
    "Ensure summaries are clear and suitable for human operators.\n",
    "\n",
    "Verifier Agent Event: {verified_claims?}\n",
    "\"\"\"\n",
    "\n",
    "summarizer_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"summarizer_agent\",\n",
    "    description=\"Summarizer agent in the AgentFleet incident response system\",\n",
    "    instruction=SUMMARIZER_AGENT_INSTRUCTIONS,\n",
    "    tools=[extract_key_facts_tool],\n",
    "    output_key=\"incident_brief\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Summarizer Agent Successfully Setup\")\n",
    "print(\"   Model: gemini-2.5-flash-lite\")\n",
    "print(\"   Tool: extract_key_facts_tool()\")\n",
    "print(\"   Ready to summarize verified events into incident briefs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4860bf0",
   "metadata": {},
   "source": [
    "![Summarizer Agent](../demo/summarizer_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cfcb45",
   "metadata": {},
   "source": [
    "## 5. Triage Agent Setup\n",
    "\n",
    "The Triage Agent is the fourth component in the AgentFleet pipeline. It receives incident briefs from the Summarizer Agent and classifies them by severity level to prioritize emergency response.\n",
    "\n",
    "### 5.1 Import Triage Tools\n",
    "\n",
    "We begin by importing the specialized tools that the Triage Agent uses to classify incidents and manage the response queue:\n",
    "\n",
    "The Triage Agent performs the following functions:\n",
    "\n",
    "- **Receives incident briefs** from the Summarizer Agent with key facts and summaries\n",
    "- **Analyzes incident content** to determine the appropriate severity classification\n",
    "- **Classifies incidents** into four levels: LOW, MEDIUM, HIGH, or CRITICAL\n",
    "- **Calculates priority scores** (0.0 to 1.0) for incident ordering and dispatch sequencing\n",
    "- **Creates job queue entries** for HIGH and CRITICAL incidents to alert response teams\n",
    "- **Forwards triaged incidents** to the Dispatcher Agent for action generation\n",
    "\n",
    "**Severity Classification Guidelines:**\n",
    "- **CRITICAL**: Immediate threat to life, major infrastructure failure, widespread impact (>1000 affected)\n",
    "- **HIGH**: Significant threat, infrastructure damage, regional impact (100â€“1000 affected)\n",
    "- **MEDIUM**: Moderate threat, localized damage, limited impact (10â€“100 affected)\n",
    "- **LOW**: Minor threat, minimal damage, very limited impact (<10 affected)\n",
    "\n",
    "**Key Capabilities:**\n",
    "- Intelligent severity analysis based on multiple factors (threat level, scope, casualties)\n",
    "- Priority scoring for efficient incident sequencing\n",
    "- Job queue creation for automated escalation\n",
    "- Reasoning transparency for operator review and audit trails\n",
    "\n",
    "This agent serves as the critical decision point in the pipeline, ensuring that limited emergency resources are deployed to the most urgent incidents first, ultimately saving lives through intelligent prioritization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "060ebac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Triage Agent created to classify incident severity and create job entries.\n",
      "   Ready to receive incident briefs and perform triage.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%writefile -a fleet-agent/agent.py\n",
    "\n",
    "from capstone.agents.triage_agent import (\n",
    "    classify_severity_tool,\n",
    "    create_job_tool,\n",
    "    )\n",
    "\n",
    "TRIAGE_AGENT_INSTRUCTION = \"\"\"You are the Triage Agent in the AgentFleet incident response system.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Receive incident briefs from the Summarizer Agent\n",
    "2. Analyze incident content to determine severity level\n",
    "3. Classify incidents as LOW, MEDIUM, HIGH, or CRITICAL based on:\n",
    "   - Threat to life or safety\n",
    "   - Infrastructure impact\n",
    "   - Geographic scope\n",
    "   - Number of people affected\n",
    "   - Urgency of response needed\n",
    "4. Calculate priority scores (0.0 to 1.0) for incident ordering\n",
    "5. Create job queue entries for HIGH and CRITICAL incidents\n",
    "6. Forward triaged incidents to the Dispatcher Agent\n",
    "\n",
    "Severity Classification Guidelines:\n",
    "- CRITICAL: Immediate threat to life, major infrastructure failure, widespread impact (>1000 affected)\n",
    "- HIGH: Significant threat, infrastructure damage, regional impact (100-1000 affected)\n",
    "- MEDIUM: Moderate threat, localized damage, limited impact (10-100 affected)\n",
    "- LOW: Minor threat, minimal damage, very limited impact (<10 affected)\n",
    "\n",
    "When processing incidents:\n",
    "- Use the `classify_severity_tool` to analyze and classify incidents\n",
    "- Use the `create_job_tool` to create job entries for HIGH and CRITICAL incidents\n",
    "- Always provide clear reasoning for severity assignments\n",
    "- Consider reliability scores when making classifications\n",
    "- Explain your reasoning in the output, including which factors influenced the severity classification\n",
    "\n",
    "Be decisive and consistent in your classifications.\n",
    "Prioritize human safety and infrastructure integrity.\n",
    "\n",
    "Summarizer Agent Event: {incident_brief?}\n",
    "\"\"\"\n",
    "\n",
    "triage_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"triage_agent\",\n",
    "    description=\"Classify incident severity as LOW, MEDIUM, HIGH, or CRITICAL with priority score\",\n",
    "    instruction=TRIAGE_AGENT_INSTRUCTION,\n",
    "    tools=[classify_severity_tool, create_job_tool],\n",
    "    output_key=\"triage_result\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Triage Agent created to classify incident severity and create job entries.\")\n",
    "print(\"   Ready to receive incident briefs and perform triage.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f9b76",
   "metadata": {},
   "source": [
    "![Triage Agent](../demo/triage_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e08ce3",
   "metadata": {},
   "source": [
    "## 6. Dispatcher Agent Setup\n",
    "\n",
    "The Dispatcher Agent is the fifth and final component in the AgentFleet pipeline. It receives triaged incidents from the Triage Agent and converts them into concrete action plans, communication templates, and persistent records for emergency response teams.\n",
    "\n",
    "### 6.1 Import Dispatcher Tools\n",
    "\n",
    "We begin by importing the specialized tools that the Dispatcher Agent uses to generate actions, create communications, and persist incident data:\n",
    "\n",
    "The Dispatcher Agent performs the following functions:\n",
    "\n",
    "- **Receives triaged incidents** from the Triage Agent with severity classifications and priority scores\n",
    "- **Generates recommended actions** with specific steps, responsible parties, and realistic timelines\n",
    "- **Creates communication templates** for HIGH and CRITICAL severity incidents to alert response teams\n",
    "- **Persists incident data** to the database for historical tracking and audit trails\n",
    "- **Notifies the Operator Dashboard** to make incidents immediately visible to human operators\n",
    "- **Updates job status** to mark incidents as processed and ready for response\n",
    "\n",
    "**Action Generation Guidelines:**\n",
    "- Provide specific, actionable recommendations tailored to severity level\n",
    "- Assign clear responsible parties (e.g., Fire Department, Police, Emergency Medical Services)\n",
    "- Include realistic response timelines based on incident severity and scope\n",
    "- Prioritize human safety and critical infrastructure protection above all else\n",
    "- Scale response scope appropriately (e.g., local response for LOW, regional coordination for CRITICAL)\n",
    "\n",
    "**Communication Template Guidelines:**\n",
    "- Use professional, clear, and concise language suitable for emergency personnel\n",
    "- Include all critical incident information (ID, severity level, location, brief summary)\n",
    "- List the top 3â€“5 priority actions in order of importance\n",
    "- Provide contact information placeholders for inter-agency coordination\n",
    "- Set clear expectations for next status updates and response milestones\n",
    "\n",
    "**Key Capabilities:**\n",
    "- Multi-format action generation (structured recommendations for automated systems)\n",
    "- Template-based communication for rapid team briefing\n",
    "- Complete incident data persistence for regulatory compliance and post-incident analysis\n",
    "- Real-time dashboard updates for situational awareness\n",
    "- Seamless integration with existing emergency response infrastructure\n",
    "\n",
    "This agent serves as the bridge between intelligent incident analysis and human-driven emergency response, ensuring that operators have everything needed to act decisively and effectively. By automating routine communication and documentation tasks, the Dispatcher Agent frees response teams to focus on saving lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37a7a550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dispatcher Agent created to generate actions, persist incidents, and notify dashboard.\n",
      "   Ready to receive triaged incidents and perform dispatching.\n"
     ]
    }
   ],
   "source": [
    "# %%writefile -a fleet-agent/agent.py\n",
    "\n",
    "from capstone.agents.dispatcher_agent import (\n",
    "    generate_actions_tool,\n",
    "    create_communication_template_tool,\n",
    "    persist_incident_tool,\n",
    "    notify_dashboard_tool,\n",
    ")\n",
    "\n",
    "DISPATCHER_AGENT_INSTRUCTION = \"\"\"You are the Dispatcher Agent in the AgentFleet incident response system.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Receive triaged incidents from the Triage Agent\n",
    "2. Generate recommended actions with specific steps, responsible parties, and timelines\n",
    "3. Create communication templates for HIGH and CRITICAL severity incidents\n",
    "4. Persist complete incident data to the database\n",
    "5. Update job status to COMPLETED\n",
    "6. Notify the Operator Dashboard of new incidents\n",
    "\n",
    "Action Generation Guidelines:\n",
    "- Provide specific, actionable recommendations\n",
    "- Assign clear responsible parties\n",
    "- Include realistic timelines based on severity\n",
    "- Prioritize human safety and infrastructure protection\n",
    "- Scale response appropriately to severity level\n",
    "\n",
    "Communication Template Guidelines:\n",
    "- Use professional, clear language\n",
    "- Include all critical information (ID, severity, location, summary)\n",
    "- List top priority actions\n",
    "- Provide contact information placeholders\n",
    "- Set expectations for next updates\n",
    "\n",
    "When processing incidents:\n",
    "- Use the `generate_actions_tool` to create recommended actions\n",
    "- Use the `create_communication_template_tool` for HIGH/CRITICAL incidents\n",
    "- Use the `persist_incident_tool` to save to database\n",
    "- Use the `notify_dashboard_tool` to make incident available to operators\n",
    "- Always ensure complete data persistence\n",
    "- Confirm job status is updated to COMPLETED\n",
    "\n",
    "Be thorough and professional in all communications.\n",
    "Ensure operators have all information needed to respond effectively.\n",
    "\n",
    "Triage Agent Event: {triage_result?}\n",
    "\"\"\"\n",
    "\n",
    "dispatcher_agent = LlmAgent(\n",
    "    name=\"dispatcher_agent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    description=\"Dispatcher agent in the AgentFleet incident response system\",\n",
    "    instruction=DISPATCHER_AGENT_INSTRUCTION,\n",
    "    tools=[\n",
    "        generate_actions_tool,\n",
    "        create_communication_template_tool,\n",
    "        persist_incident_tool,\n",
    "        notify_dashboard_tool,\n",
    "    ],\n",
    "    output_key=\"dispatch_result\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Dispatcher Agent created to generate actions, persist incidents, and notify dashboard.\")\n",
    "print(\"   Ready to receive triaged incidents and perform dispatching.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dea2ed",
   "metadata": {},
   "source": [
    "![Dispatcher Agent](../demo/dispatcher_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8908d82",
   "metadata": {},
   "source": [
    "### Dashboard Agent Setup\n",
    "The Dashboard Agent is an additional component in the AgentFleet pipeline. It receives dispatched incidents from the Dispatcher Agent and creates markdown dashboards for human operators to visualize and manage emergency response operations.\n",
    "\n",
    "The Dashboard Agent performs the following functions:\n",
    "- **Receives dispatched incidents** from the Dispatcher Agent with recommended actions and communication templates\n",
    "- **Generates markdown dashboards** that summarize incident details, severity levels, recommended actions, and status updates\n",
    "- **Organizes dashboards** for easy navigation and quick reference by human operators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bb6eb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dashboard Agent created to create and maintain incident response dashboard.\n",
      "   Model: gemini-2.5-flash-lite\n",
      "   Tool: create_dashboard_markdown_tool()\n",
      "   Ready to create markdown dashboards from dispatched incidents.\n"
     ]
    }
   ],
   "source": [
    "# %%writefile -a fleet-agent/agent.py\n",
    "\n",
    "DASHBOARD_AGENT_INSTRUCTION = \"\"\"You are the Dashboard Agent in the AgentFleet incident response system.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Access the INCIDENT_CACHE from the Dispatcher Agent to get current incident data\n",
    "2. Create and maintain an incident dashboard with all current incidents\n",
    "3. Display incident information in a clear, organized markdown table format\n",
    "4. Include all relevant fields: incident ID, severity, status, location, priority score, actions, and timestamps\n",
    "5. Update the dashboard with new incidents as they are dispatched\n",
    "\n",
    "Dashboard Requirements:\n",
    "- Create a markdown table with the following columns:\n",
    "  - Incident ID\n",
    "  - Severity Level (LOW/MEDIUM/HIGH/CRITICAL)\n",
    "  - Status (DISPATCHED, IN_PROGRESS, RESOLVED, etc.)\n",
    "  - Priority Score (0.0-1.0)\n",
    "  - Location (if available)\n",
    "  - Summary (brief description)\n",
    "  - Actions Required (count of recommended actions)\n",
    "  - Dispatched At (timestamp)\n",
    "- Sort incidents by severity (CRITICAL â†’ HIGH â†’ MEDIUM â†’ LOW) and then by priority score (highest first)\n",
    "- Include all dispatched incidents in the dashboard\n",
    "- Format timestamps in a readable format (YYYY-MM-DD HH:MM UTC)\n",
    "- Keep summaries concise (max 50 characters)\n",
    "- Display the dashboard as markdown output that can be rendered in notebooks\n",
    "- Highlight critical and high-priority incidents with detailed action items\n",
    "- Include communication templates for critical/high incidents\n",
    "\n",
    "When processing incidents:\n",
    "- Use the `create_dashboard_markdown_tool` to generate the dashboard from cache\n",
    "- The tool automatically accesses the INCIDENT_CACHE from the Dispatcher Agent\n",
    "- Focus on presenting information clearly for human operator review\n",
    "- Ensure critical incidents are prominently displayed with action items\n",
    "\n",
    "Be thorough in presenting all incident information clearly.\n",
    "Focus on readability and actionable information for operators.\n",
    "\n",
    "The dashboard will automatically reflect the current state of all dispatched incidents.\n",
    "\"\"\"\n",
    "\n",
    "from capstone.agents.dashboard_agent import create_dashboard_markdown_tool\n",
    "\n",
    "dashboard_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"dashboard_agent\",\n",
    "    description=\"Dashboard agent to create and maintain incident response dashboard\",\n",
    "    instruction=DASHBOARD_AGENT_INSTRUCTION,\n",
    "    tools=[create_dashboard_markdown_tool],\n",
    "    output_key=\"dashboard_output\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Dashboard Agent created to create and maintain incident response dashboard.\")\n",
    "print(\"   Model: gemini-2.5-flash-lite\")\n",
    "print(\"   Tool: create_dashboard_markdown_tool()\")\n",
    "print(\"   Ready to create markdown dashboards from dispatched incidents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fabedd4",
   "metadata": {},
   "source": [
    "![Dashboard Agent](../demo/dashboard_agent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "059c9537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Root Agent created to coordinate Ingest, Verifier, Summarizer, Triage, and Dispatcher agents.\n",
      "   Ready to manage end-to-end event ingestion, verification, summarization, triage, and dispatch.\n",
      "\n",
      "============================================================\n",
      "âœ… Root Agent Runner created.\n",
      "   Ready to run end-to-end event ingestion, verification, summarization, triage, and dispatch workflows.\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Root agent to coordinate ingest and verifier agents\n",
    "\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"root_agent\",\n",
    "    description=\"Root agent to coordinate Ingest, Verifier, Summarizer, Triage, and Dispatcher agents in the AgentFleet incident response system\",\n",
    "    sub_agents=[remote_ingest_agent, verifier_agent, summarizer_agent, triage_agent, dispatcher_agent],\n",
    ")\n",
    "print(\"âœ… Root Agent created to coordinate Ingest, Verifier, Summarizer, Triage, and Dispatcher agents.\")\n",
    "print(\"   Ready to manage end-to-end event ingestion, verification, summarization, triage, and dispatch.\")\n",
    "print()\n",
    "print(\"===\" * 20)\n",
    "\n",
    "# Root agent runner\n",
    "root_agent_runner = InMemoryRunner(\n",
    "    agent=root_agent,\n",
    "    app_name=\"root_agent_app\",\n",
    ")\n",
    "print(\"âœ… Root Agent Runner created.\")\n",
    "print(\"   Ready to run end-to-end event ingestion, verification, summarization, triage, and dispatch workflows.\")\n",
    "print()\n",
    "print(\"===\" * 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed6ea1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8001/.well-known/agent-card.json \"HTTP/1.1 200 OK\"\n",
      "INFO:a2a.client.card_resolver:Successfully fetched agent card data from http://localhost:8001/.well-known/agent-card.json: {'capabilities': {}, 'defaultInputModes': ['text/plain'], 'defaultOutputModes': ['text/plain'], 'description': 'Ingest agent that connects to event sources and extract imformation for processing', 'name': 'ingest_agent', 'preferredTransport': 'JSONRPC', 'protocolVersion': '0.3.0', 'skills': [{'description': 'Ingest agent that connects to event sources and extract imformation for processing I am the Ingest Agent in the AgentFleet incident response system.\\n\\nmy responsibilities:\\n1. Call `generate_single_event` to generate a single event from a specified source.\\n2. The event output should be described in detail for further processing.\\n\\nWhen processing events:\\n- Use the `generate_single_event` tool to generate events\\n- If the event is successfully generated, describe the generated event in detail \\n- Generate unique event IDs\\n- Extract all relevant information from the event source and describe it in detail\\n\\nUser will supply the source to extract from e.g \"twitter\", \"emergency_feed\", or \"sensor_data\". Pass this to the `generate_single_event` tool to generate the event.\\nThen describe the generated event in detail in my output.\\n', 'id': 'ingest_agent', 'name': 'model', 'tags': ['llm']}, {'description': 'Generate a single event from the specified source type.\\n\\nArgs:\\n    source_type: Type of stream source (\"twitter\", \"emergency\", \"sensor\")\\n\\nReturns:\\n    Dictionary containing the generated event data\\n\\nRaises:\\n    ValueError: If source_type is not supported', 'id': 'ingest_agent-generate_single_event', 'name': 'generate_single_event', 'tags': ['llm', 'tools']}], 'supportsAuthenticatedExtendedCard': False, 'url': 'http://localhost:8001', 'version': '0.0.1'}\n",
      "INFO:google_adk.google.adk.agents.remote_a2a_agent:Successfully resolved remote A2A agent: remote_ingest_agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Root Agent to Ingest, Verify, Summarize, Triage, and Dispatch Events ===\n",
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Ingest latest events from twitter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8001 \"HTTP/1.1 200 OK\"\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote_ingest_agent > The event was generated successfully from the twitter source.\n",
      "\n",
      "Event ID: 0b6a237c-d0a0-4e08-9cc5-44e59649603d\n",
      "Event Source: twitter\n",
      "Timestamp: 2025-11-29T21:59:09.438792\n",
      "\n",
      "Event Details:\n",
      "A structure fire is occurring on Main Street with heavy smoke reported. The tweet was posted by user_7123 and has 832 likes and 273 retweets. The incident type is classified as a fire.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_adk.google.adk.models.google_llm:Response received from the model.\n",
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "INFO:capstone.agents.verifier_agent:Extracted 2 claims from event\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "INFO:google_adk.google.adk.models.google_llm:Response received from the model.\n",
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "INFO:capstone.agents.verifier_agent:Verified claim with confidence 0.27\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "INFO:google_adk.google.adk.models.google_llm:Response received from the model.\n",
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "INFO:capstone.agents.verifier_agent:Verified claim with confidence 0.31\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "INFO:google_adk.google.adk.models.google_llm:Response received from the model.\n",
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "INFO:capstone.agents.verifier_agent:Calculated reliability score: 0.37\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "INFO:google_adk.google.adk.models.google_llm:Response received from the model.\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verifier_agent > The event from twitter has been analyzed. The following claims were extracted:\n",
      "1. \"A structure fire is occurring on Main Street with heavy smoke reported\"\n",
      "2. \"The tweet was posted by user_7123 and has 832 likes and 273 retweets\"\n",
      "\n",
      "Verification results:\n",
      "- Claim 1 was not verified. There were no corroborating sources found, and the confidence score was low (0.27).\n",
      "- Claim 2 was verified. Although no external sources were used for verification in this instance, the claim pertains to tweet-specific metadata, which is considered inherently verifiable by the platform. The confidence score was 0.31.\n",
      "\n",
      "Overall reliability:\n",
      "The overall reliability score for this event is 0.37. This score is based on one verified claim out of two extracted claims (50% verification rate) and an average confidence score of 0.29. While the event contains some verifiable information, the lack of external corroboration for the primary assertion (structure fire) leads to a moderate reliability score. Further verification is recommended for the unverified claims.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_adk.google.adk.models.google_llm:Response received from the model.\n",
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "INFO:capstone.agents.summarizer_agent:Extracted 1 key facts\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "INFO:google_adk.google.adk.models.google_llm:Response received from the model.\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarizer_agent > A structure fire was reported on Main Street with heavy smoke. The original tweet was posted by user_7123 and received 832 likes and 273 retweets.\n",
      "\n",
      "**Key Facts:**\n",
      "*   **Location:** Main Street\n",
      "*   **Time:** 2025-11-29T21:59:09.438792\n",
      "*   **Affected Entity:** A structure\n",
      "*   **Impact:** Heavy smoke reported; classified as a fire.\n",
      "*   **Source:** Twitter (user_7123)\n",
      "*   **Engagement:** 832 likes, 273 retweets\n",
      "\n",
      "**Reasoning:**\n",
      "The primary claim regarding the structure fire was not externally verified (confidence: 0.27), though the tweet's metadata (likes, retweets) was considered inherently verifiable (confidence: 0.31). The overall reliability score is 0.37. Due to the unverified nature of the core incident report, further investigation into the fire claim is recommended. The key facts extracted focus on the reported details and the source of the information, while also noting the low confidence in the fire report itself. The incident type was included as 'fire' based on the provided event details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_adk.google.adk.models.google_llm:Response received from the model.\n",
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "INFO:capstone.agents.triage_agent:Classified incident as LOW (priority: 0.10)\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "INFO:google_adk.google.adk.models.google_llm:Response received from the model.\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "INFO:google_adk.google.adk.models.google_llm:Response received from the model.\n",
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "INFO:capstone.agents.dispatcher_agent:Generated 3 recommended actions for incident 0b6a237c-d0a0-4e08-9cc5-44e59649603d\n",
      "ERROR:capstone.agents.dispatcher_agent:Error persisting incident: no such table: incidents\n",
      "INFO:capstone.agents.dispatcher_agent:Added incident 0b6a237c-d0a0-4e08-9cc5-44e59649603d to dashboard cache\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "INFO:google_adk.google.adk.models.google_llm:Response received from the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispatcher_agent > The incident has been logged and the dashboard has been updated. Recommended actions are:\n",
      "- Log incident for record keeping and trend analysis (Responsible: Operations Center, Timeline: Within 24 hours)\n",
      "- Review and update standard operating procedures if needed (Responsible: Planning Section, Timeline: Within 1 week)\n",
      "- Coordinate with local authorities in Main Street (Responsible: Regional Coordinator, Timeline: As appropriate for severity level)\n",
      "\n",
      "The incident data could not be persisted to the database due to a table not being found. Please ensure the database is set up correctly.\n"
     ]
    }
   ],
   "source": [
    "# agent in action\n",
    "print(\"\\n=== Running Root Agent to Ingest, Verify, Summarize, Triage, and Dispatch Events ===\")\n",
    "response = await root_agent_runner.run_debug(\"Ingest latest events from twitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ed039ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if fleet-agent folder does not exist, create it\n",
    "if not os.path.exists(\"fleet-agent\"):\n",
    "    !adk create fleet-agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "694e2b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run web server for the fleet-agent\n",
    "RUN_ADK_WEB_SERVER = False\n",
    "if RUN_ADK_WEB_SERVER:\n",
    "    !adk web --log_level DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87dd6e",
   "metadata": {},
   "source": [
    "![Demo](../demo/agent-fleet.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449e87b9",
   "metadata": {},
   "source": [
    "## 7. Demo Summary\n",
    "\n",
    "This demonstration showcased the AgentFleet multi-agent emergency response system, highlighting how specialized AI agents can collaborate to ingest, verify, summarize, triage, dispatch, and visualize emergency incidents. By automating critical tasks and providing actionable insights, AgentFleet aims to enhance community safety and support first responders in saving lives.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
